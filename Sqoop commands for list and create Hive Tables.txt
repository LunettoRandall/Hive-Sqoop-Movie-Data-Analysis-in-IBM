
# Take data from MySQL DB to your HDFS using Sqoop.

sqoop list-databases --connect jdbc:mysql://150.136.19.248 --username hadoop --password cisbigdata


# List the tables in the movielens database.

sqoop list-tables --connect jdbc:mysql://150.136.19.248/movielens --username hadoop --password cisbigdata


# Import the movie table into Hadoop Hive table and specify that the data is directly added to Hive.

sqoop import --connect jdbc:mysql://150.136.19.248/movielens --driver com.mysql.jdbc.Driver --table movie --fields-terminated-by '\t' --username hadoop --password cisbigdata --hive-import


# Create users table with --hive-table option from user table of MYSQL DB, which conflict the name of the existing Hive table:

sqoop import --connect jdbc:mysql://150.136.19.248/movielens --driver com.mysql.jdbc.Driver --table user --fields-terminated-by '\t' --username hadoop --password cisbigdata --hive-import --hive-table users

